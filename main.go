package main

import (
	"strings"

	"github.com/stoewer/go-strcase"
	"google.golang.org/protobuf/compiler/protogen"
	"google.golang.org/protobuf/reflect/protoreflect"
)

func main() {
	protogen.Options{}.Run(func(gen *protogen.Plugin) error {
		for _, file := range gen.Files {
			if !file.Generate {
				continue
			}
			dataloaders := getDataloadersFromFile(file)
			if len(dataloaders) == 0 {
				continue
			}
			g := gen.NewGeneratedFile(file.GeneratedFilenamePrefix+generatedFilenameSuffix, file.GoImportPath)
			g.P("// Code generated by protoc-gen-go-aip-dataloader. DO NOT EDIT.")
			g.P("package ", file.GoPackageName)
			g.P()
			for _, d := range dataloaders {
				genType(g, d)
				genBatchType(g, d)
				genConstructor(g, d)
				genFetchFn(g, d)
				genLoadMethod(g, d)
				genLoadThunkMethod(g, d)
				genLoadAllMethod(g, d)
				genLoadAllThunkMethod(g, d)
				genPrimeMethod(g, d)
				genClearMethod(g, d)
				genUnsafeSetMethod(g, d)
				genKeyIndexMethod(g, d)
				genStartTimerMethod(g, d)
				genEndMethod(g, d)
			}
		}
		return nil
	})
}

const generatedFilenameSuffix = "_dataloader.go"

func genType(g *protogen.GeneratedFile, d *Dataloader) {
	timeDuration := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "time",
		GoName:       "Duration",
	})
	syncMutex := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "sync",
		GoName:       "Mutex",
	})
	contextContext := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "context",
		GoName:       "Context",
	})
	g.P()
	g.P("// ", d.Name(), " is a dataloader for ", d.Method.Desc.FullName(), ".")
	g.P("type ", d.Name(), " struct {")
	g.P("ctx ", contextContext)
	g.P("client ", d.ClientName())
	g.P("requestTemplate *", d.Method.Input.GoIdent)
	g.P("wait ", timeDuration)
	g.P("maxBatch int")
	g.P("mu ", syncMutex, " // protects mutable state below")
	g.P("cache map[string]", d.OutputType())
	g.P("batch *", d.BatchName())
	g.P("}")
}

func genBatchType(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("type ", d.BatchName(), " struct {")
	g.P("keys []string")
	g.P("data []", d.OutputType())
	g.P("err error")
	g.P("closing bool")
	g.P("done chan struct{}")
	g.P("}")
}

func genConstructor(g *protogen.GeneratedFile, d *Dataloader) {
	timeDuration := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "time",
		GoName:       "Duration",
	})
	contextContext := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "context",
		GoName:       "Context",
	})
	g.P()
	g.P("// New", d.Name(), " creates a new dataloader for ", d.Method.Desc.FullName(), ".")
	g.P("func New", d.Name(), "(")
	g.P("ctx ", contextContext, ",")
	g.P("client ", d.ClientName(), ",")
	g.P("requestTemplate *", d.Method.Input.GoIdent, ",")
	g.P("wait ", timeDuration, ",")
	g.P("maxBatch int,")
	g.P(") *", d.Name(), " {")
	g.P("return &", d.Name(), "{")
	g.P("ctx: ctx,")
	g.P("client: client,")
	g.P("requestTemplate: requestTemplate,")
	g.P("wait: wait,")
	g.P("maxBatch: maxBatch,")
	g.P("}")
	g.P("}")
}

func genFetchFn(g *protogen.GeneratedFile, d *Dataloader) {
	protoClone := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "google.golang.org/protobuf/proto",
		GoName:       "Clone",
	})
	g.P()
	g.P("func (l *", d.Name(), ") fetch(keys []string) ([]", d.OutputType(), ", error) {")
	g.P("request := ", protoClone, "(l.requestTemplate).(*", d.Method.Input.GoIdent, ")")
	g.P("request.", d.InputField.GoName, " = keys")
	g.P("response, err := l.client.", d.Method.GoName, "(l.ctx, request)")
	g.P("if err != nil {")
	g.P("return nil, err")
	g.P("}")
	g.P("return response.", d.OutputField.GoName, ", nil")
	g.P("}")
}

func genLoadMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("// Load a result by key, batching and caching will be applied automatically.")
	g.P("func (l *", d.Name(), ") Load(key string) (", d.OutputType(), ", error) {")
	fmtErrorf := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "fmt",
		GoName:       "Errorf",
	})
	g.P("if l == nil {")
	g.P("return ", d.OutputZero(), ", ", fmtErrorf, `("`, d.Name(), ` is nil")`)
	g.P("}")
	g.P("return l.LoadThunk(key)()")
	g.P("}")
}

func genLoadThunkMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("// LoadThunk returns a function that when called will block waiting for a result.")
	g.P("// This method should be used if you want one goroutine to make requests to many")
	g.P("// different data loaders without blocking until the thunk is called.")
	g.P("func (l *", d.Name(), ") LoadThunk(key string) func() (", d.OutputType(), ", error) {")
	fmtErrorf := g.QualifiedGoIdent(protogen.GoIdent{
		GoImportPath: "fmt",
		GoName:       "Errorf",
	})
	g.P("if l == nil {")
	g.P("return func() (", d.OutputType(), ", error) {")
	g.P("return ", d.OutputZero(), ", ", fmtErrorf, `("`, d.Name(), ` is nil")`)
	g.P("}")
	g.P("}")
	g.P("l.mu.Lock()")
	g.P("if it, ok := l.cache[key]; ok {")
	g.P("l.mu.Unlock()")
	g.P("return func() (", d.OutputType(), ", error) {")
	g.P("return it, nil")
	g.P("}")
	g.P("}")
	g.P("if l.batch == nil {")
	g.P("l.batch = &", d.BatchName(), "{done: make(chan struct{})}")
	g.P("}")
	g.P("batch := l.batch")
	g.P("pos := batch.keyIndex(l, key)")
	g.P("l.mu.Unlock()")
	g.P("return func() (", d.OutputType(), ", error) {")
	g.P("<-batch.done")
	g.P("var data ", d.OutputType())
	g.P("if pos < len(batch.data) {")
	g.P("data = batch.data[pos]")
	g.P("}")
	g.P("if batch.err == nil {")
	g.P("l.mu.Lock()")
	g.P("l.unsafeSet(key, data)")
	g.P("l.mu.Unlock()")
	g.P("}")
	g.P("return data, batch.err")
	g.P("}")
	g.P("}")
}

func genLoadAllMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("// LoadAll fetches many keys at once.")
	g.P("// It will be broken into appropriately sized sub-batches based on how the dataloader is configured.")
	g.P("func (l *", d.Name(), ") LoadAll(keys []string) ([]", d.OutputType(), ", error) {")
	g.P("results := make([]func() (", d.OutputType(), ", error), len(keys))")
	g.P("for i, key := range keys {")
	g.P("results[i] = l.LoadThunk(key)")
	g.P("}")
	g.P("values := make([]", d.OutputType(), ", len(keys))")
	g.P("var err error")
	g.P("for i, thunk := range results {")
	g.P("values[i], err = thunk()")
	g.P("if err != nil {")
	g.P("return nil, err")
	g.P("}")
	g.P("}")
	g.P("return values, nil")
	g.P("}")
}

func genLoadAllThunkMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("// LoadAllThunk returns a function that when called will block waiting for results.")
	g.P("// This method should be used if you want one goroutine to make requests to many")
	g.P("// different data loaders without blocking until the thunk is called.")
	g.P("func (l *", d.Name(), ") LoadAllThunk(keys []string) (func() ([]", d.OutputType(), ", error)) {")
	g.P("results := make([]func() (", d.OutputType(), ", error), len(keys))")
	g.P("for i, key := range keys {")
	g.P("results[i] = l.LoadThunk(key)")
	g.P("}")
	g.P("return func() ([]", d.OutputType(), ", error) {")
	g.P("values := make([]", d.OutputType(), ", len(keys))")
	g.P("var err error")
	g.P("for i, thunk := range results {")
	g.P("values[i], err = thunk()")
	g.P("if err != nil {")
	g.P("return nil, err")
	g.P("}")
	g.P("}")
	g.P("return values, nil")
	g.P("}")
	g.P("}")
}

func genPrimeMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P("// Prime the cache with the provided key and value. If the key already exists, no change is made")
	g.P("// and false is returned.")
	g.P("// (To forcefully prime the cache, clear the key first with loader.clear(key).prime(key, value).)")
	g.P("func (l *", d.Name(), ") Prime(key string, value ", d.OutputType(), ") bool {")
	g.P("if l == nil {")
	g.P("return false")
	g.P("}")
	g.P("l.mu.Lock()")
	g.P("var found bool")
	g.P("if _, found = l.cache[key]; !found {")
	g.P("// make a copy when writing to the cache, its easy to pass a pointer in from a loop var")
	g.P("// and end up with the whole cache pointing to the same value.")
	switch d.OutputField.Desc.Kind() {
	case protoreflect.MessageKind:
		protoClone := g.QualifiedGoIdent(protogen.GoIdent{
			GoImportPath: "google.golang.org/protobuf/proto",
			GoName:       "Clone",
		})
		g.P("l.unsafeSet(key, ", protoClone, "(value).(", d.OutputType(), "))")
	default:
		g.P("l.unsafeSet(key, value)")
	}
	g.P("}")
	g.P("l.mu.Unlock()")
	g.P("return !found")
	g.P("}")
	g.P()
}

func genClearMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("// Clear the value at key from the cache, if it exists.")
	g.P("func (l *", d.Name(), ") Clear(key string) {")
	g.P("if l == nil {")
	g.P("return")
	g.P("}")
	g.P("l.mu.Lock()")
	g.P("delete(l.cache, key)")
	g.P("l.mu.Unlock()")
	g.P("}")
}

func genUnsafeSetMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("func (l *", d.Name(), ") unsafeSet(key string, value ", d.OutputType(), ") {")
	g.P("if l.cache == nil {")
	g.P("l.cache = map[string]", d.OutputType(), "{}")
	g.P("}")
	g.P("l.cache[key] = value")
	g.P("}")
}

func genKeyIndexMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("// keyIndex will return the location of the key in the batch, if its not found")
	g.P("// it will add the key to the batch.")
	g.P("func (b *", d.BatchName(), ") keyIndex(l *", d.Name(), ", key string) int {")
	g.P("for i, existingKey := range b.keys {")
	g.P("if key == existingKey {")
	g.P("return i")
	g.P("}")
	g.P("}")
	g.P("pos := len(b.keys)")
	g.P("b.keys = append(b.keys, key)")
	g.P("if pos == 0 {")
	g.P("go b.startTimer(l)")
	g.P("}")
	g.P("if l.maxBatch != 0 && pos >= l.maxBatch-1 {")
	g.P("if !b.closing {")
	g.P("b.closing = true")
	g.P("l.batch = nil")
	g.P("go b.end(l)")
	g.P("}")
	g.P("}")
	g.P("return pos")
	g.P("}")
}

func genStartTimerMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("func (b *", d.BatchName(), ") startTimer(l *", d.Name(), ") {")
	g.P("time.Sleep(l.wait)")
	g.P("l.mu.Lock()")
	g.P("// we must have hit a batch limit and are already finalizing this batch")
	g.P("if b.closing {")
	g.P("l.mu.Unlock()")
	g.P("return")
	g.P("}")
	g.P("l.batch = nil")
	g.P("l.mu.Unlock()")
	g.P("b.end(l)")
	g.P("}")
}

func genEndMethod(g *protogen.GeneratedFile, d *Dataloader) {
	g.P()
	g.P("func (b *", d.BatchName(), ") end(l *", d.Name(), ") {")
	g.P("b.data, b.err = l.fetch(b.keys)")
	g.P("close(b.done)")
	g.P("}")
}

type Dataloader struct {
	Method  *protogen.Method
	Service *protogen.Service
	// TODO: Parent field support.
	InputField  *protogen.Field
	OutputField *protogen.Field
}

func (d *Dataloader) OutputType() string {
	switch d.OutputField.Desc.Kind() {
	case protoreflect.StringKind:
		return "string"
	default:
		return "*" + d.OutputField.Message.GoIdent.GoName
	}
}

func (d *Dataloader) Name() string {
	return strings.TrimPrefix(strings.TrimPrefix(string(d.Method.Desc.Name()), "Batch"), "Get") + "Dataloader"
}

func (d *Dataloader) ClientName() string {
	return d.Service.GoName + "Client"
}

func (d *Dataloader) BatchName() string {
	return strcase.LowerCamelCase(d.Name()) + "Batch"
}

func (d *Dataloader) OutputZero() string {
	switch d.OutputField.Desc.Kind() {
	case protoreflect.MessageKind, protoreflect.BytesKind:
		return "nil"
	case protoreflect.StringKind:
		return `""`
	default:
		return "0"
	}
}

func getDataloadersFromFile(file *protogen.File) []*Dataloader {
	var result []*Dataloader
	for _, service := range file.Services {
		for _, method := range service.Methods {
			if !strings.HasPrefix(string(method.Desc.Name()), "Batch") {
				continue
			}
			var inputField *protogen.Field
			for _, field := range method.Input.Fields {
				if !field.Desc.IsList() {
					continue
				}
				if field.Desc.Kind() != protoreflect.StringKind {
					continue
				}
				inputField = field
				break
			}
			if inputField == nil {
				continue
			}
			var outputField *protogen.Field
			for _, field := range method.Output.Fields {
				if !field.Desc.IsList() {
					continue
				}
				outputField = field
				break
			}
			if outputField == nil {
				continue
			}
			switch outputField.Desc.Kind() {
			case protoreflect.MessageKind, protoreflect.StringKind: // supported
			default:
				continue // not supported
			}
			result = append(result, &Dataloader{
				Method:      method,
				Service:     service,
				InputField:  inputField,
				OutputField: outputField,
			})
		}
	}
	return result
}
